# Time Series Forecasting and Deep Learning

List of research papers focus on time series forecasting and deep learning, as well as other resources like competitions, datasets, courses, blogs, code, etc.

## Table of Contents

- [Papers](#Papers)
- [Competitions](#Competitions)
- [Courses](#Courses)
- [Blogs](#Blogs)
- [Libraries](#Libraries)
- [Datasets](#Datasets)
- [Books](#Books)

## Papers

### 2022

* [Formal Algorithms for Transformers](https://arxiv.org/abs/2207.09238)
  
  * 19 Jul 2022, Mary Phuong, Marcus Hutter
- [Less Is More: Fast Multivariate Time Series Forecasting with
  Light Sampling-oriented MLP Structures](https://arxiv.org/abs/2207.01186)
  
  - 4 Jul 2022, Tianping Zhang, et al.

- [Are Transformers Effective for Time Series Forecasting?](https://arxiv.org/abs/2205.13504)
  
  - 26 May 2022, Ailing Zeng, et al.
  
  - [[Code](https://github.com/cure-lab/DLinear)]

- [Transformers in Time Series: A Survey](https://arxiv.org/abs/2202.07125)
  
  - 15 Feb 2022, Qingsong Wen, et al.
  
  - [[Code](https://github.com/qingsongedu/time-series-transformers-review)]

- [FEDformer: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting](https://arxiv.org/abs/2201.12740)
  
  - 30 Jan 2022, Tian Zhou, et al.
  
  - [[Code](https://github.com/MAZiqing/FEDformer)]

### 2021

* [HIST: A Graph-based Framework for Stock Trend Forecasting via Mining Concept-Oriented Shared Information](https://arxiv.org/abs/2110.13716)
  
  * 26 Oct 2021, Wentao Xu, et al.
  
  * [[Code](https://github.com/wentao-xu/hist)]

* [Pyraformer: Low-Complexity Pyramidal Attention for Long-Range Time Series Modeling and Forecasting](https://openreview.net/forum?id=0EXmFzUn5I)
  
  * 29 Sept 2021, Shizhan Liu, et al.
  
  * [[Code](https://github.com/alipay/Pyraformer)]

* [Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting](https://arxiv.org/abs/2106.13008)
  
  * 24 Jun 2021, Haixu Wu, et al.
  
  * [[Code](https://github.com/thuml/Autoformer)]

* [TS2Vec: Towards Universal Representation of Time Series](https://arxiv.org/abs/2106.10466)
  
  * 19 Jun 2021, Zhihan Yue, et al.
  
  * [[Code](https://github.com/yuezhihan/ts2vec)]

* [Time Series is a Special Sequence: Forecasting with Sample Convolution and Interaction](https://arxiv.org/abs/2106.09305)
  
  * 17 Jun 2021, Minhao Liu, et al. 
  
  * [[Code](https://github.com/cure-lab/SCINet)]

* [Neural basis expansion analysis with exogenous variables: Forecasting electricity prices with NBEATSx](https://arxiv.org/abs/2104.05522)
  
  * 12 Apr 2021, Kin G. Olivares, et al.
  
  * [[Code](https://github.com/cchallu/nbeatsx)]

* [Perceiver: General Perception with Iterative Attention](https://arxiv.org/abs/2103.03206)
  
  * 4 Mar 2021, Andrew Jaegle, et al.
  
  * [[Official Code](https://github.com/deepmind/deepmind-research/tree/master/perceiver)] [[Community Code](https://github.com/lucidrains/perceiver-pytorch)]

* [Do We Really Need Deep Learning Models for Time Series Forecasting?](https://arxiv.org/abs/2101.02118)
  
  * 6 Jan 2021, Shereen Elsayed, et al.
  
  * [[Code](https://github.com/Daniela-Shereen/GBRT-for-TSF)]

### 2020

* [Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting](https://arxiv.org/abs/2012.07436)
  
  * 14 Dec 2020, Haoyi Zhou, et al.
  
  * [[Code](https://github.com/zhouhaoyi/Informer2020)]

* [A Transformer-based Framework for Multivariate Time Series Representation Learning](https://arxiv.org/abs/2010.02803)
  
  * 6 Oct 2020, George Zerveas, et al.
  
  * [[Code](https://github.com/gzerveas/mvts_transformer)]

### 2019

* [Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting](https://arxiv.org/abs/1912.09363)
  
  * 19 Dec 2019, Bryan Lim, et al.
  
  * [[Code](https://github.com/mattsherar/Temporal_Fusion_Transform)]

* [High-Dimensional Multivariate Forecasting with Low-Rank Gaussian Copula Processes](https://arxiv.org/abs/1910.03002)
  
  * 7 Oct 2019, David Salinas, et al.
  
  * [[Code](https://github.com/awslabs/gluon-ts/tree/dev/src/gluonts/mx/model/gpvar)]

* [Time2Vec: Learning a Vector Representation of Time](https://arxiv.org/abs/1907.05321)
  
  * 11 Jul 2019, Seyed Mehran Kazemi, et al.
  
  * [[Code](https://github.com/ojus1/Time2Vec-PyTorch)]

* [Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting](https://arxiv.org/abs/1907.00235)
  
  * 29 Jun 2019, Shiyang Li, et al.
  
  * [[Code](https://github.com/mlpotter/Transformer_Time_Series)]

* [N-BEATS: Neural basis expansion analysis for interpretable time series forecasting](https://arxiv.org/abs/1905.10437)
  
  * 24 May 2019, Boris N. Oreshkin, et al.
  
  * [[Code](https://github.com/ElementAI/N-BEATS)]

### 2017

* [Graph Attention Networks](https://arxiv.org/abs/1710.10903)
  
  * 30 Oct 2017, Petar Veličković, et al.
  
  * [[Code](https://github.com/PetarV-/GAT)]

* [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
  
  * 12 Jun 2017, Ashish Vaswani, et al.
  
  * [[Code](https://github.com/huggingface/transformers)]

* [DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks](https://arxiv.org/abs/1704.04110)
  
  * 13 Apr 2017, David Salinas, et al.
  
  * [[Code](https://github.com/jdb78/pytorch-forecasting)]

## Competitions

- [Ubiquant Market Prediction](https://www.kaggle.com/competitions/ubiquant-market-prediction)

## Courses

- [CS25: Transformers United](https://web.stanford.edu/class/cs25/)

## Blogs

- [The Annotated Transformer](http://nlp.seas.harvard.edu/annotated-transformer/)
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)

## Libraries

* [Darts](https://unit8co.github.io/darts/)
  
  * `Darts` is a Python library for easy manipulation and forecasting of time series.
  
  * [[Github](https://github.com/unit8co/darts)]

* [NeuralForecast](https://nixtla.github.io/neuralforecast/)
  
  * `NeuralForecast` is a Python library for time series forecasting with deep learning models. 
  
  * [[Github](https://github.com/Nixtla/neuralforecast)]

* [Kats](https://facebookresearch.github.io/Kats/)
  
  * `Kats` is a toolkit to analyze time series data, a lightweight, easy-to-use, and generalizable framework to perform time series analysis.
  
  * [[Github](https://github.com/facebookresearch/kats)]

* [PyTorch Forecasting](https://pytorch-forecasting.readthedocs.io/en/stable/)
  
  * `PyTorch Forecasting` is a PyTorch-based package for forecasting time series with state-of-the-art network architectures.
  
  * [[Github](https://github.com/jdb78/pytorch-forecasting)]

* [Prophet](https://facebook.github.io/prophet/)
  
  * `Prophet` is a forecasting procedure implemented in R and Python. It is fast and provides completely automated forecasts that can be tuned by hand by data scientists and analysts.
  
  * [[Github](https://github.com/facebook/prophet)]

* AutoTS
  
  * `AutoTS` is a time series package for Python designed for rapidly deploying high-accuracy forecasts at scale.
  
  * [[Github](https://github.com/winedarksea/AutoTS)]

* Merlion
  
  * `Merlion` is a Python library for time series intelligence. It provides an end-to-end machine learning framework that includes loading and transforming data, building and training models, post-processing model outputs, and evaluating model performance.
  
  * [[Github](https://github.com/salesforce/Merlion)]

* PyTorchTS
  
  * `PyTorchTS` is a [PyTorch](https://github.com/pytorch/pytorch) Probabilistic Time Series forecasting framework which provides state of the art PyTorch time series models by utilizing [GluonTS](https://github.com/awslabs/gluon-ts) as its back-end API and for loading, transforming and back-testing time series data sets.
  
  * [[Github](https://github.com/zalandoresearch/pytorch-ts)]

* [Qlib](https://qlib.readthedocs.io/en/latest/)
  
  * `Qlib` is an AI-oriented quantitative investment platform, which aims to realize the potential, empower the research, and create the value of AI technologies in quantitative investment.
  
  * [[Github](https://github.com/microsoft/qlib)]

* [Flow Forecast](https://flow-forecast.atlassian.net/wiki/spaces/FF/overview)
  
  * `Flow Forecast` is a deep learning PyTorch library for time series forecasting, classification, and anomaly detection.
  
  * [[Github](https://github.com/AIStream-Peelout/flow-forecast)]

* [pyts](https://pyts.readthedocs.io/en/stable/)
  
  * `pyts` is a Python package dedicated to time series classification. It aims to make time series classification easily accessible by providing preprocessing and utility tools, and implementations of several time series classification algorithms.
  
  * [[Github](https://github.com/johannfaouzi/pyts)]

* [Greykite](https://linkedin.github.io/greykite/)
  
  * The `Greykite` library provides flexible, intuitive and fast forecasts through its flagship algorithm, Silverkite.
  
  * [[Github](https://github.com/linkedin/greykite)]

## Datasets

* [Monash Time Series Forecasting Repository](https://forecastingdata.org/)
  
  * The first repository containing datasets of related time series for global forecasting
  
  * [[Dataset](https://zenodo.org/communities/forecasting)]
  
  * [[Github](https://github.com/rakshitha123/TSForecasting)]

* Electricity Transformer Dataset (ETDataset)
  
  * The `Electricity Transformer Dataset` is collected to support the further investigation on the long sequence forecasting problem.
  
  * [[Github](https://github.com/zhouhaoyi/ETDataset)]

* [Open Source Asset Pricing](https://www.openassetpricing.com/)
  
  * [[Data](https://www.openassetpricing.com/data/)]
  
  * [[Github](https://github.com/OpenSourceAP/CrossSection/)]
  
  * [[Paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3604626)]

* [UEA & UCR Time Series Classification Repository](https://www.timeseriesclassification.com/)
  
  * [[Data](https://www.timeseriesclassification.com/dataset.php)]

## Books

* Forecasting: Principles and Practice (3rd ed)
  
  * *Rob J Hyndman and George Athanasopoulos, 2021*
  
  * This textbook is intended to provide a comprehensive introduction to forecasting methods and to present enough information about each method for readers to be able to use them sensibly.
  
  * [[Website](https://otexts.com/fpp3/)]
